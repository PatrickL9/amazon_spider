2023-02-01 16:28:42 [scrapy.utils.log] INFO: Scrapy 2.6.3 started (bot: amazon_spider)
2023-02-01 16:28:42 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 21.2.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 16:07:46) [MSC v.1900 32 bit (Intel)], pyOpenSSL 23.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 39.0.0, Platform Windows-10-10.0.19041-SP0
2023-02-01 16:28:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 16:28:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 16:28:42 [scrapy.extensions.telnet] INFO: Telnet Password: 354e596cbd38666c
2023-02-01 16:28:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 16:28:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 16:28:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 16:28:42 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 16:28:42 [scrapy.core.engine] INFO: Spider opened
2023-02-01 16:28:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 16:28:42 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 16:28:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 16:28:42 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 16:28:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.xdaili.cn:80
2023-02-01 16:28:42 [urllib3.connectionpool] DEBUG: http://api.xdaili.cn:80 "GET /xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 103
2023-02-01 16:28:42 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\connections.py", line 353, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\connections.py", line 633, in connect
    self._request_authentication()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\connections.py", line 921, in _request_authentication
    auth_packet = self._process_auth(plugin_name, auth_packet)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\connections.py", line 957, in _process_auth
    return _auth.caching_sha2_password_auth(self, auth_packet)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\_auth.py", line 266, in caching_sha2_password_auth
    pkt = _roundtrip(conn, data)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\_auth.py", line 120, in _roundtrip
    pkt = conn._read_packet()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.OperationalError: (1045, "Access denied for user 'craw_data'@'localhost' (using password: YES)")
2023-02-01 16:28:42 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 16:28:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.151466,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 8, 28, 42, 704423),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 8, 28, 42, 552957)}
2023-02-01 16:28:42 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 16:38:39 [scrapy.utils.log] INFO: Scrapy 2.6.3 started (bot: amazon_spider)
2023-02-01 16:38:39 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 21.2.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 23.0.0 (OpenSSL 3.0.7 1 Nov 2022), cryptography 39.0.0, Platform Windows-10-10.0.19041-SP0
2023-02-01 16:38:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 16:38:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 16:38:39 [scrapy.extensions.telnet] INFO: Telnet Password: 07203410d0493a25
2023-02-01 16:38:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 16:38:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 16:38:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 16:38:39 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 16:38:39 [scrapy.core.engine] INFO: Spider opened
2023-02-01 16:38:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 16:38:39 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 16:38:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 16:38:39 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 16:38:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.xdaili.cn:80
2023-02-01 16:38:40 [urllib3.connectionpool] DEBUG: http://api.xdaili.cn:80 "GET /xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 107
2023-02-01 16:38:40 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 152, in _next_request
    request = next(self.slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 353, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 633, in connect
    self._request_authentication()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 921, in _request_authentication
    auth_packet = self._process_auth(plugin_name, auth_packet)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 957, in _process_auth
    return _auth.caching_sha2_password_auth(self, auth_packet)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\_auth.py", line 266, in caching_sha2_password_auth
    pkt = _roundtrip(conn, data)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\_auth.py", line 120, in _roundtrip
    pkt = conn._read_packet()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 725, in _read_packet
    packet.raise_for_error()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\protocol.py", line 221, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\err.py", line 143, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.OperationalError: (1045, "Access denied for user 'craw_data'@'localhost' (using password: YES)")
2023-02-01 16:38:40 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 16:38:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.146511,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 8, 38, 40, 74129),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 8, 38, 39, 927618)}
2023-02-01 16:38:40 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:23:29 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:23:29 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:23:29 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:23:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:23:29 [scrapy.extensions.telnet] INFO: Telnet Password: 1b45b6bc768f8d5c
2023-02-01 17:23:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:23:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:23:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:23:29 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:23:29 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:23:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:23:29 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:23:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:23:29 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:23:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:23:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:23:29 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:23:29 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:23:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.134461,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 23, 29, 874133),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 23, 29, 739672)}
2023-02-01 17:23:29 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:24:12 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:24:12 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:24:12 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:24:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:24:12 [scrapy.extensions.telnet] INFO: Telnet Password: afafccc0409fabb6
2023-02-01 17:24:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:24:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:24:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:24:12 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:24:12 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:24:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:24:12 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:24:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:24:12 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:24:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:24:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:24:12 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:24:12 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:24:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.104713,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 24, 12, 874994),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 24, 12, 770281)}
2023-02-01 17:24:12 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:24:53 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:24:53 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:24:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:24:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:24:53 [scrapy.extensions.telnet] INFO: Telnet Password: f53ac38dff12dd23
2023-02-01 17:24:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:24:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:24:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:24:53 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:24:53 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:24:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:24:53 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:24:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:24:53 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:24:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:24:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 105
2023-02-01 17:24:54 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:24:54 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:24:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.108573,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 24, 54, 100247),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 24, 53, 991674)}
2023-02-01 17:24:54 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:27:46 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:27:46 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:27:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:27:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:27:46 [scrapy.extensions.telnet] INFO: Telnet Password: 9bc082693f4ef00c
2023-02-01 17:27:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:27:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:27:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:27:46 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:27:46 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:27:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:27:46 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:27:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:27:46 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:27:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:27:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:27:46 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:27:46 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:27:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.146402,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 27, 46, 756480),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 27, 46, 610078)}
2023-02-01 17:27:46 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:28:17 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:28:17 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:28:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:28:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:28:17 [scrapy.extensions.telnet] INFO: Telnet Password: a75345e65a99bd5c
2023-02-01 17:28:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:28:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:28:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:28:17 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:28:17 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:28:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:28:17 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:28:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:28:17 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:28:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:28:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 109
2023-02-01 17:28:17 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:28:17 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:28:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.11148,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 28, 17, 807517),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 28, 17, 696037)}
2023-02-01 17:28:17 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:29:39 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:29:39 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:29:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:29:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:29:39 [scrapy.extensions.telnet] INFO: Telnet Password: 7a4a4d838fdf1da8
2023-02-01 17:29:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:29:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:29:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:29:40 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:29:40 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:29:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:29:40 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:29:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:29:40 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:29:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:29:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 107
2023-02-01 17:29:40 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 64, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:29:40 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:29:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.116581,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 29, 40, 260843),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 29, 40, 144262)}
2023-02-01 17:29:40 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:34:00 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:34:00 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:34:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:34:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:34:00 [scrapy.extensions.telnet] INFO: Telnet Password: 9e8be2fe64ea52d3
2023-02-01 17:34:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:34:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:34:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:34:00 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:34:00 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:34:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:34:00 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:34:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:34:00 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:34:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:34:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 112
2023-02-01 17:34:00 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:34:00 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:34:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.12993,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 34, 0, 503669),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 34, 0, 373739)}
2023-02-01 17:34:00 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:35:40 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:35:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:35:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:35:51 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:35:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:35:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:35:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:35:51 [scrapy.extensions.telnet] INFO: Telnet Password: 5d8951543f3c62f9
2023-02-01 17:35:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:35:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:35:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:35:52 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:35:52 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:35:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:35:52 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:35:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:35:52 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:35:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:35:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 105
2023-02-01 17:35:52 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:35:52 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:35:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.102739,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 35, 52, 156849),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 35, 52, 54110)}
2023-02-01 17:35:52 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:36:13 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:36:13 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:36:13 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:36:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:36:13 [scrapy.extensions.telnet] INFO: Telnet Password: 20338cc40e5226ec
2023-02-01 17:36:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:36:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:36:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:36:13 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:36:13 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:36:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:36:13 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:36:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:36:13 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:36:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:36:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 106
2023-02-01 17:36:14 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:36:14 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:36:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.141071,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 36, 14, 130559),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 36, 13, 989488)}
2023-02-01 17:36:14 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:36:52 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:36:52 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:36:52 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:37:00 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:37:00 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:37:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:37:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:37:00 [scrapy.extensions.telnet] INFO: Telnet Password: e9611984fa03dfe5
2023-02-01 17:37:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:37:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:37:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:37:00 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:37:00 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:37:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:37:00 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:37:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:37:00 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:37:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:37:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 109
2023-02-01 17:37:01 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:37:01 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:37:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.108848,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 37, 1, 10492),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 37, 0, 901644)}
2023-02-01 17:37:01 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:37:32 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:37:32 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:37:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:37:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:37:32 [scrapy.extensions.telnet] INFO: Telnet Password: bd2c5e8e63115071
2023-02-01 17:37:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:37:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:37:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:37:32 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:37:32 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:37:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:37:32 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:37:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:37:48 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:37:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:37:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 107
2023-02-01 17:37:49 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:37:49 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:37:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 16.522863,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 37, 49, 102736),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 37, 32, 579873)}
2023-02-01 17:37:49 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:38:02 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:38:02 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:38:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:38:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:38:02 [scrapy.extensions.telnet] INFO: Telnet Password: 8284d227d9c0367f
2023-02-01 17:38:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:38:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:38:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:38:02 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:38:02 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:38:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:38:02 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:38:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:38:28 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:38:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:38:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:38:28 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:38:28 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:38:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 26.01008,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 38, 28, 178273),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 38, 2, 168193)}
2023-02-01 17:38:28 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:40:49 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:40:49 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:40:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:40:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:40:49 [scrapy.extensions.telnet] INFO: Telnet Password: 7c348133398ec404
2023-02-01 17:40:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:40:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:40:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:40:49 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:40:49 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:40:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:40:49 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:40:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:40:49 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:40:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:40:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:40:49 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 63, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 10, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:40:49 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:40:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.113463,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 40, 49, 773849),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 40, 49, 660386)}
2023-02-01 17:40:49 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:43:55 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:43:55 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:43:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:43:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:43:55 [scrapy.extensions.telnet] INFO: Telnet Password: aa821c7727a354ce
2023-02-01 17:43:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:43:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:43:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:43:55 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:43:55 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:43:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:43:55 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:43:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:43:55 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:43:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:43:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 109
2023-02-01 17:43:56 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:43:56 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:43:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.117236,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 43, 56, 42444),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 43, 55, 925208)}
2023-02-01 17:43:56 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:45:18 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:45:18 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:45:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:45:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:45:18 [scrapy.extensions.telnet] INFO: Telnet Password: b52bff5513955999
2023-02-01 17:45:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:45:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:45:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:45:18 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:45:18 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:45:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:45:18 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:45:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:45:18 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:45:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:45:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:45:18 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:45:18 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:45:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.109895,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 45, 18, 326767),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 45, 18, 216872)}
2023-02-01 17:45:18 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:54:08 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:54:08 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:54:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:54:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:54:08 [scrapy.extensions.telnet] INFO: Telnet Password: d185871c4b980a2f
2023-02-01 17:54:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:54:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:54:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:54:08 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:54:08 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:54:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:54:08 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:54:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:54:08 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:54:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:54:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 107
2023-02-01 17:54:08 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:54:08 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:54:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.133418,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 54, 8, 893658),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 54, 8, 760240)}
2023-02-01 17:54:08 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:54:59 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:54:59 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:54:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:54:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:54:59 [scrapy.extensions.telnet] INFO: Telnet Password: dfcdec1b3974308f
2023-02-01 17:54:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:54:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:54:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:54:59 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:54:59 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:54:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:54:59 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:54:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:54:59 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:54:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:54:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 17:54:59 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:54:59 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:54:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.113474,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 54, 59, 568755),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 54, 59, 455281)}
2023-02-01 17:54:59 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:55:43 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:55:43 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:55:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:55:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:55:43 [scrapy.extensions.telnet] INFO: Telnet Password: ece54cb758318c54
2023-02-01 17:55:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:55:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:55:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:55:43 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:55:43 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:55:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:55:43 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:55:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:55:43 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:55:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:55:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 107
2023-02-01 17:55:44 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:55:44 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:55:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.102234,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 55, 44, 86145),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 55, 43, 983911)}
2023-02-01 17:55:44 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 17:59:30 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 17:59:30 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 17:59:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 17:59:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 17:59:30 [scrapy.extensions.telnet] INFO: Telnet Password: 5ebd24214faf599c
2023-02-01 17:59:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 17:59:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 17:59:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 17:59:31 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 17:59:31 [scrapy.core.engine] INFO: Spider opened
2023-02-01 17:59:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 17:59:31 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 17:59:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 17:59:31 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 17:59:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 17:59:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 109
2023-02-01 17:59:31 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 17:59:31 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 17:59:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.135737,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 9, 59, 31, 286732),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 9, 59, 31, 150995)}
2023-02-01 17:59:31 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 18:01:46 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 18:01:46 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 18:01:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 18:01:46 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 18:01:46 [scrapy.extensions.telnet] INFO: Telnet Password: bba0b96ed3cb8a53
2023-02-01 18:01:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 18:01:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 18:01:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 18:01:46 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 18:01:46 [scrapy.core.engine] INFO: Spider opened
2023-02-01 18:01:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 18:01:46 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 18:01:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 18:01:46 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 18:01:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 18:01:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 106
2023-02-01 18:01:46 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 18:01:46 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 18:01:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.108156,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 10, 1, 46, 876782),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 10, 1, 46, 768626)}
2023-02-01 18:01:46 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 18:02:15 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 18:02:15 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 18:02:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 18:02:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 18:02:15 [scrapy.extensions.telnet] INFO: Telnet Password: d22c1afa2684bddd
2023-02-01 18:02:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 18:02:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 18:02:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 18:02:15 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 18:02:15 [scrapy.core.engine] INFO: Spider opened
2023-02-01 18:02:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 18:02:15 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 18:02:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 18:02:15 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 18:02:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 18:02:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 112
2023-02-01 18:02:38 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 18:02:38 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 18:02:38 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 18:02:38 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 18:02:38 [scrapy.extensions.telnet] INFO: Telnet Password: 68a0616f5953e0e3
2023-02-01 18:02:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 18:02:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 18:02:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 18:02:39 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 18:02:39 [scrapy.core.engine] INFO: Spider opened
2023-02-01 18:02:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 18:02:39 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 18:02:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 18:02:39 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 18:02:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 18:02:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 18:02:39 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 18:02:39 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 18:02:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.111418,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 10, 2, 39, 177321),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 10, 2, 39, 65903)}
2023-02-01 18:02:39 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 18:03:01 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 18:03:01 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 18:03:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 18:03:01 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 18:03:01 [scrapy.extensions.telnet] INFO: Telnet Password: f33e023856a2c3ec
2023-02-01 18:03:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 18:03:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 18:03:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 18:03:01 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 18:03:01 [scrapy.core.engine] INFO: Spider opened
2023-02-01 18:03:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 18:03:01 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 18:03:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 18:03:01 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 18:03:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 18:03:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 109
2023-02-01 18:03:04 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 18:03:04 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 18:03:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 2.621373,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 10, 3, 4, 395494),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 10, 3, 1, 774121)}
2023-02-01 18:03:04 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:32:03 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:32:03 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:32:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:32:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:32:03 [scrapy.extensions.telnet] INFO: Telnet Password: 9910cd822d416296
2023-02-01 21:32:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:32:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:32:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:32:03 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:32:03 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:32:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:32:03 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:32:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:32:03 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:32:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:32:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 21:32:03 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:32:03 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:32:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.137931,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 32, 3, 816494),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 32, 3, 678563)}
2023-02-01 21:32:03 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:32:20 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:32:20 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:32:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:32:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:32:20 [scrapy.extensions.telnet] INFO: Telnet Password: 94b789fc5352075a
2023-02-01 21:32:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:32:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:32:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:32:20 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:32:20 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:32:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:32:20 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:32:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:32:20 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:32:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:32:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 112
2023-02-01 21:32:21 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:32:21 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:32:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.111792,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 32, 21, 81093),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 32, 20, 969301)}
2023-02-01 21:32:21 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:33:58 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:33:58 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:33:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:33:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:33:58 [scrapy.extensions.telnet] INFO: Telnet Password: 5a9b7ff763cbc8e0
2023-02-01 21:33:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:33:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:33:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:33:58 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:33:58 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:33:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:33:58 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:33:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:33:58 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:33:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:33:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 104
2023-02-01 21:33:58 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:33:58 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:33:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.113779,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 33, 58, 875323),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 33, 58, 761544)}
2023-02-01 21:33:58 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:34:22 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:34:22 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:34:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:34:22 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:34:22 [scrapy.extensions.telnet] INFO: Telnet Password: 9de5bef8641ff296
2023-02-01 21:34:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:34:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:34:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:34:22 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:34:22 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:34:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:34:22 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:34:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:34:22 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:34:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:34:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 105
2023-02-01 21:34:23 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:34:23 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:34:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.109705,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 34, 23, 78963),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 34, 22, 969258)}
2023-02-01 21:34:23 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:42:06 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:42:06 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:42:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:42:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:42:06 [scrapy.extensions.telnet] INFO: Telnet Password: 3cb95977f1375835
2023-02-01 21:42:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:42:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:42:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:42:06 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:42:06 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:42:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:42:06 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:42:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:42:06 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:42:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:42:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 112
2023-02-01 21:42:07 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "c:\users\administrator\appdata\local\programs\python\python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:42:07 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:42:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.135745,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 42, 7, 49410),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 42, 6, 913665)}
2023-02-01 21:42:07 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:42:14 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:42:14 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:42:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:42:40 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:42:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:42:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:42:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:42:40 [scrapy.extensions.telnet] INFO: Telnet Password: 743eb02ce2d3b04f
2023-02-01 21:42:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:42:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:42:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:42:40 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:42:40 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:42:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:42:40 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:42:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:42:40 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:42:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:42:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 107
2023-02-01 21:42:40 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 67, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:42:40 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:42:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.109558,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 42, 40, 330483),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 42, 40, 220925)}
2023-02-01 21:42:40 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:43:04 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:43:04 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:43:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:43:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:43:04 [scrapy.extensions.telnet] INFO: Telnet Password: d5a69f065d355bcb
2023-02-01 21:43:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:43:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:43:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:43:05 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:43:05 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:43:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:43:05 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:43:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:43:05 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:43:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:43:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 108
2023-02-01 21:43:05 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 67, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port = 3306, charset = 'utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:43:05 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:43:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.118644,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 43, 5, 209006),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 43, 5, 90362)}
2023-02-01 21:43:05 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:45:07 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:45:07 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:45:07 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:45:07 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:45:07 [scrapy.extensions.telnet] INFO: Telnet Password: 4f1312420b0ed01b
2023-02-01 21:45:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:45:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:45:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:45:07 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:45:07 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:45:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:45:07 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:45:07 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:45:07 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:45:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:45:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 110
2023-02-01 21:45:07 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 67, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port=3306, charset='utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:45:07 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:45:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.110496,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 45, 7, 962867),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 45, 7, 852371)}
2023-02-01 21:45:07 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:45:36 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:45:36 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:45:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:45:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:45:36 [scrapy.extensions.telnet] INFO: Telnet Password: 32cf850dc70c840a
2023-02-01 21:45:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:45:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:45:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:45:36 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:45:36 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:45:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:45:36 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:45:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:45:36 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:45:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:45:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 105
2023-02-01 21:45:36 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 67, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port=3306, charset='utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:45:36 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:45:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.114992,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 45, 36, 931021),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 45, 36, 816029)}
2023-02-01 21:45:36 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:46:08 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:46:08 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:46:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:46:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:46:08 [scrapy.extensions.telnet] INFO: Telnet Password: 0394015b981d6b26
2023-02-01 21:46:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:46:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:46:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:46:08 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:46:08 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:46:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:46:08 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:46:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:46:08 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:46:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:46:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 103
2023-02-01 21:46:08 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 68, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 13, in __init__
    port=3306, charset='utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:46:08 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:46:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.129272,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 46, 8, 909742),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 46, 8, 780470)}
2023-02-01 21:46:08 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:46:45 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:46:45 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:46:45 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:46:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:46:45 [scrapy.extensions.telnet] INFO: Telnet Password: 9de221fb716ec2da
2023-02-01 21:46:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:46:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:46:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:46:45 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:46:45 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:46:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:46:45 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:46:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:46:45 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:46:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:46:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 110
2023-02-01 21:46:45 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 68, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 14, in __init__
    port=3306, charset='utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:46:46 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:46:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.118105,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 46, 46, 62),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 46, 45, 881957)}
2023-02-01 21:46:46 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 21:47:33 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 21:47:33 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 21:47:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 21:47:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 21:47:33 [scrapy.extensions.telnet] INFO: Telnet Password: 5089d23b800de8af
2023-02-01 21:47:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 21:47:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 21:47:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 21:47:33 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 21:47:33 [scrapy.core.engine] INFO: Spider opened
2023-02-01 21:47:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 21:47:33 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 21:47:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 21:47:33 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 21:47:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:7890
2023-02-01 21:47:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:7890 "GET http://api.xdaili.cn/xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 106
2023-02-01 21:47:35 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\scrapy\core\engine.py", line 129, in _next_request
    request = next(slot.start_requests)
  File "D:\pythonProject\amazon_spider\amazon_spider\spiders\amazon.py", line 66, in start_requests
    query = DoMysql()
  File "D:\pythonProject\amazon_spider\amazon_spider\mysql_conn.py", line 14, in __init__
    port=3306, charset='utf8mb4')  # 有中文要存入数据库的话要加charset='utf8'
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\__init__.py", line 90, in Connect
    return Connection(*args, **kwargs)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 706, in __init__
    self.connect()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 931, in connect
    self._get_server_information()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\connections.py", line 1269, in _get_server_information
    self.server_charset = charset_by_id(lang).name
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\site-packages\pymysql\charset.py", line 38, in by_id
    return self._by_id[id]
KeyError: 255
2023-02-01 21:47:35 [scrapy.core.engine] INFO: Closing spider (finished)
2023-02-01 21:47:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'elapsed_time_seconds': 2.196677,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 2, 1, 13, 47, 35, 634456),
 'log_count/DEBUG': 3,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'start_time': datetime.datetime(2023, 2, 1, 13, 47, 33, 437779)}
2023-02-01 21:47:35 [scrapy.core.engine] INFO: Spider closed (finished)
2023-02-01 22:06:43 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: amazon_spider)
2023-02-01 22:06:43 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 3.4.8, Platform Windows-10-10.0.19041-SP0
2023-02-01 22:06:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2023-02-01 22:06:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'amazon_spider',
 'CONCURRENT_REQUESTS': 24,
 'COOKIES_ENABLED': False,
 'DOWNLOADER_CLIENT_TLS_CIPHERS': 'DEFAULT:!DH',
 'DOWNLOAD_DELAY': 0.8,
 'DOWNLOAD_TIMEOUT': 300,
 'LOG_FILE': 'log/scrapy_2023_2_1.log',
 'NEWSPIDER_MODULE': 'amazon_spider.spiders',
 'RETRY_TIMES': 1,
 'SPIDER_MODULES': ['amazon_spider.spiders']}
2023-02-01 22:06:43 [scrapy.extensions.telnet] INFO: Telnet Password: 512ec090a22ffd7e
2023-02-01 22:06:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-02-01 22:06:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'amazon_spider.middlewares.AmazonSpiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'amazon_spider.middlewares.fail_retry_middleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-02-01 22:06:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-02-01 22:06:43 [scrapy.middleware] INFO: Enabled item pipelines:
['amazon_spider.pipelines.MysqlasynPipeline']
2023-02-01 22:06:43 [scrapy.core.engine] INFO: Spider opened
2023-02-01 22:06:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-02-01 22:06:43 [amazon_crawl] INFO: Spider opened: amazon_crawl
2023-02-01 22:06:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-02-01 22:06:43 [amazon_crawl] DEBUG: ------------获取首批代理ip----------------
2023-02-01 22:06:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.xdaili.cn:80
2023-02-01 22:06:43 [urllib3.connectionpool] DEBUG: http://api.xdaili.cn:80 "GET /xdaili-api//greatRecharge/getGreatIp?spiderId=460e34f07cf041899a22e79353081288&orderno=YZ2021112078186AsWJy&returnType=1&count=5 HTTP/1.1" 200 112
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----0
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 Safari/537.36
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----1
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://114.233.108.84:28521-----2
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (Kresponse, like Gecko) Chrome/91.0.4472.114 Safari/537.36
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://14.106.244.208:44499-----3
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----4
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----5
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:34.0) Gecko/20100101 Firefox/34.0
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----6
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----7
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----8
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0b13pre) Gecko/20110307 Firefox/4.0b13pre
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://14.106.244.208:44499-----9
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://14.106.244.208:44499-----10
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----11
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://114.233.108.84:28521-----12
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----13
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----14
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----15
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; LBBROWSER)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----16
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----17
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----18
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----19
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (Kresponse, like Gecko) Chrome/91.0.4472.114 Safari/537.36
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----20
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; GTB7.0)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----21
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----22
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; GTB7.0)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----23
2023-02-01 22:06:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.amazon.es/dp/B001DJIARW> (failed 1 times): Could not open CONNECT tunnel with proxy 114.233.108.84:28521 [{'status': 503, 'reason': b'Service Unavailable'}]
2023-02-01 22:06:44 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E)
2023-02-01 22:06:44 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----24
2023-02-01 22:06:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.amazon.com/dp/B0000AXOHT/?language=en_US> (failed 1 times): Could not open CONNECT tunnel with proxy 114.233.108.84:28521 [{'status': 503, 'reason': b'Service Unavailable'}]
2023-02-01 22:06:45 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (Kresponse, like Gecko) Chrome/91.0.4472.114 Safari/537.36
2023-02-01 22:06:45 [amazon_crawl] DEBUG: 更换IP:http://223.215.171.21:25855-----25
2023-02-01 22:06:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.amazon.com/dp/B0002HC2HU/?language=en_US> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2023-02-01 22:06:48 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)
2023-02-01 22:06:48 [amazon_crawl] DEBUG: 更换IP:http://140.250.148.179:48632-----26
2023-02-01 22:06:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.de/dp/B000U77Z9C/?language=de_DE> (referer: None)
2023-02-01 22:06:49 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)
2023-02-01 22:06:49 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----27
2023-02-01 22:06:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.amazon.de/dp/B000U77Z9C/?language=de_DE>
None
2023-02-01 22:06:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.amazon.de/dp/B000XRW2WO/?language=de_DE> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2023-02-01 22:06:50 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36
2023-02-01 22:06:50 [amazon_crawl] DEBUG: 更换IP:http://14.106.244.208:44499-----28
2023-02-01 22:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.fr/dp/B003HI1BBO> (referer: None)
2023-02-01 22:06:51 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)
2023-02-01 22:06:51 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----29
2023-02-01 22:06:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.amazon.fr/dp/B003HI1BBO>
None
2023-02-01 22:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.amazon.de/dp/B000MQ7E06/?language=de_DE> (referer: None)
2023-02-01 22:06:51 [amazon_crawl] DEBUG: [User-Agent]: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11
2023-02-01 22:06:51 [amazon_crawl] DEBUG: 更换IP:http://121.206.250.114:37395-----30
